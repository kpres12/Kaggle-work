{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvaHjSqw7L4CggIVL0DV32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpres12/Kaggle-work/blob/main/AI_Model_Minst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip6aR6_LDfEY"
      },
      "outputs": [],
      "source": [
        "# Ensure TensorFlow is installed\n",
        "!pip install tensorflow\n",
        "\n",
        "# Import TensorFlow and other necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, LeakyReLU, BatchNormalization, Conv2DTranspose, Conv2D, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "(x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to [-1, 1]\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# Print the shape of the training data\n",
        "print(x_train.shape)  # (60000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "Vjh_AqJID3hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "axZjqqEiEQHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "QblB5JCZEhQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "cross_entropy = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Discriminator loss\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# Generator loss\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = Adam(1e-4)\n",
        "discriminator_optimizer = Adam(1e-4)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "NOISE_DIM = 100\n",
        "NUM_EXAMPLES_TO_GENERATE = 16\n",
        "\n",
        "# Seed for visualizing progress\n",
        "seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "\n",
        "# Training step function\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "# Training function\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # Produce images for the GIF as we go\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "# Function to generate and save images\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "# Prepare the dataset\n",
        "BUFFER_SIZE = 60000\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Train the model\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "DzgyRX41EtNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some images after training\n",
        "noise = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n",
        "generated_images = generator(noise, training=False)\n",
        "\n",
        "# Visualize the generated images\n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ljfmkop_Ezcj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}